{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1va6lnIQwslzgWpXa4lQE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jamshidbek077/Deep_Learning_and_NLP_with_AI_NeuralNetworks/blob/master/Numbers_image_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kerakli  kutubxonalarnin chaqirib olish"
      ],
      "metadata": {
        "id": "jQDfabGBJS3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FNf7qBi-JDfR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import cuda\n",
        "import torch.nn as nn\n",
        "import  torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from  torchvision import datasets,transforms\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training parametrs"
      ],
      "metadata": {
        "id": "VjlObPJiKQhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "device='cuda' if cuda.is_available() else 'cpu' # GPU (CPU)da train qilish agar bolsa\n",
        "print(f\"MNST modelini {device} da train qilish\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ4G6jfpKVti",
        "outputId": "5c1dc4ec-f2a5-4a1d-bb2e-778b00f8863d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNST modelini cuda da train qilish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST data_set"
      ],
      "metadata": {
        "id": "ubAss6K5LVG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=datasets.MNIST(root='./content/train_set',\n",
        "                             train=True,\n",
        "                             transform=transforms.ToTensor(),\n",
        "                             download=True)\n",
        "\n",
        "test_dataset=datasets.MNIST(root='./content/test_set',\n",
        "                            train=False,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Na_7r2owLUG2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader (Input Pipeline)"
      ],
      "metadata": {
        "id": "uSDgXUiNNalT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)\n",
        "\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False)"
      ],
      "metadata": {
        "id": "qPJuVfo5Ng7r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRau3O9-2H9Q",
        "outputId": "f1d89d77-f98f-4628-c47b-f3f2d9e14719"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./content/train_set\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "mz6f7lYH2o4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHgxjLfI27BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True)"
      ],
      "metadata": {
        "id": "iQsI1BKH2n0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data_setimizdagi rasmlarni korish"
      ],
      "metadata": {
        "id": "9R1qTmzcYuHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Bir mini-batchni olish\n",
        "dataiter = iter(train_loader)\n",
        "images, labels =next(dataiter)\n",
        "\n",
        "# Tasvirlarni ko'rish\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for idx in np.arange(10):\n",
        "    ax = fig.add_subplot(28, 28, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(str(labels[idx].item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "id": "hfPDrwEWSlzB",
        "outputId": "73f52356-235d-47cf-bcef-188a8ca72c66"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8zHiySiWP1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Model"
      ],
      "metadata": {
        "id": "c11aeCVaQWuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.serialization import INT_SIZE\n",
        "class CNN_Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN_Net,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
        "    self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
        "    self.mp=nn.MaxPool2d(2)\n",
        "    self.fc=nn.Linear(320,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    in_size=x.size(0)\n",
        "    x=F.relu(self.mp(self.conv1(x)))\n",
        "    x=F.relu(self.mp(self.conv2(x)))\n",
        "    x=x.view(in_size,-1) # tensorni flatten yordamida olchamini\n",
        "    x=self.fc(x)\n",
        "    return F.log_softmax(x)\n",
        "\n",
        "model=CNN_Net()\n",
        "model.to(device)\n",
        "optimizer=optim.SGD(model.parameters(),lr=0.01,momentum=0.5)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data,target) in enumerate(train_loader):\n",
        "    data,target=data.to(device),target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output=model(data)\n",
        "    loss =F.nll_loss(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 10 ==0:\n",
        "       print('Train Epoch: {} | Batch Holati: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        # batchdagi loss larni yig'indisini hisoblash\n",
        "        test_loss+=F.nll_loss(output,target,size_average=False).data\n",
        "        # max qiymatning indeksini olish\n",
        "        pred = output.data.max(1, keepdim=True)[1]   # torch.max() funkisyasi har ikkala qiymat va indekslarni qaytaradi\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'\\nTest set : Average(ortach) loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "since = time.time()\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "\n",
        "  epoch_start = time.time()\n",
        "  train(epoch)\n",
        "  m, s = divmod(time.time() - epoch_start, 60)\n",
        "  print(f'Training uchun ketgan vaqt: {m:.0f}m {s:.0f}s')\n",
        "  test()\n",
        "  m, s = divmod(time.time() - epoch_start, 60)\n",
        "  print(f'Test uchun ketgan vaqt: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "m, s = divmod(time.time() - since, 60)\n",
        "print(f'Umumiy vaqt: {m:.0f}m {s:.0f}s\\nModel  {device} qurilmada train qilindi!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3T3SlYpQVio",
        "outputId": "5abfedbc-00ac-4266-8b14-aca057cc8314"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-6b92dc3bf326>:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 | Batch Holati: 0/60000 (0%) | Loss: 2.310198\n",
            "Train Epoch: 1 | Batch Holati: 640/60000 (1%) | Loss: 2.300462\n",
            "Train Epoch: 1 | Batch Holati: 1280/60000 (2%) | Loss: 2.294249\n",
            "Train Epoch: 1 | Batch Holati: 1920/60000 (3%) | Loss: 2.254533\n",
            "Train Epoch: 1 | Batch Holati: 2560/60000 (4%) | Loss: 2.270188\n",
            "Train Epoch: 1 | Batch Holati: 3200/60000 (5%) | Loss: 2.259580\n",
            "Train Epoch: 1 | Batch Holati: 3840/60000 (6%) | Loss: 2.256296\n",
            "Train Epoch: 1 | Batch Holati: 4480/60000 (7%) | Loss: 2.219277\n",
            "Train Epoch: 1 | Batch Holati: 5120/60000 (9%) | Loss: 2.203341\n",
            "Train Epoch: 1 | Batch Holati: 5760/60000 (10%) | Loss: 2.147978\n",
            "Train Epoch: 1 | Batch Holati: 6400/60000 (11%) | Loss: 2.087954\n",
            "Train Epoch: 1 | Batch Holati: 7040/60000 (12%) | Loss: 1.989222\n",
            "Train Epoch: 1 | Batch Holati: 7680/60000 (13%) | Loss: 1.898537\n",
            "Train Epoch: 1 | Batch Holati: 8320/60000 (14%) | Loss: 1.740075\n",
            "Train Epoch: 1 | Batch Holati: 8960/60000 (15%) | Loss: 1.476820\n",
            "Train Epoch: 1 | Batch Holati: 9600/60000 (16%) | Loss: 1.268839\n",
            "Train Epoch: 1 | Batch Holati: 10240/60000 (17%) | Loss: 1.032303\n",
            "Train Epoch: 1 | Batch Holati: 10880/60000 (18%) | Loss: 0.877185\n",
            "Train Epoch: 1 | Batch Holati: 11520/60000 (19%) | Loss: 0.863658\n",
            "Train Epoch: 1 | Batch Holati: 12160/60000 (20%) | Loss: 0.608654\n",
            "Train Epoch: 1 | Batch Holati: 12800/60000 (21%) | Loss: 0.620710\n",
            "Train Epoch: 1 | Batch Holati: 13440/60000 (22%) | Loss: 0.768971\n",
            "Train Epoch: 1 | Batch Holati: 14080/60000 (23%) | Loss: 0.581528\n",
            "Train Epoch: 1 | Batch Holati: 14720/60000 (25%) | Loss: 0.596377\n",
            "Train Epoch: 1 | Batch Holati: 15360/60000 (26%) | Loss: 0.348715\n",
            "Train Epoch: 1 | Batch Holati: 16000/60000 (27%) | Loss: 0.520590\n",
            "Train Epoch: 1 | Batch Holati: 16640/60000 (28%) | Loss: 0.404456\n",
            "Train Epoch: 1 | Batch Holati: 17280/60000 (29%) | Loss: 0.295584\n",
            "Train Epoch: 1 | Batch Holati: 17920/60000 (30%) | Loss: 0.290818\n",
            "Train Epoch: 1 | Batch Holati: 18560/60000 (31%) | Loss: 0.294859\n",
            "Train Epoch: 1 | Batch Holati: 19200/60000 (32%) | Loss: 0.611098\n",
            "Train Epoch: 1 | Batch Holati: 19840/60000 (33%) | Loss: 0.338829\n",
            "Train Epoch: 1 | Batch Holati: 20480/60000 (34%) | Loss: 0.444089\n",
            "Train Epoch: 1 | Batch Holati: 21120/60000 (35%) | Loss: 0.582557\n",
            "Train Epoch: 1 | Batch Holati: 21760/60000 (36%) | Loss: 0.371599\n",
            "Train Epoch: 1 | Batch Holati: 22400/60000 (37%) | Loss: 0.356465\n",
            "Train Epoch: 1 | Batch Holati: 23040/60000 (38%) | Loss: 0.313698\n",
            "Train Epoch: 1 | Batch Holati: 23680/60000 (39%) | Loss: 0.418580\n",
            "Train Epoch: 1 | Batch Holati: 24320/60000 (41%) | Loss: 0.350989\n",
            "Train Epoch: 1 | Batch Holati: 24960/60000 (42%) | Loss: 0.859182\n",
            "Train Epoch: 1 | Batch Holati: 25600/60000 (43%) | Loss: 0.352323\n",
            "Train Epoch: 1 | Batch Holati: 26240/60000 (44%) | Loss: 0.411918\n",
            "Train Epoch: 1 | Batch Holati: 26880/60000 (45%) | Loss: 0.355798\n",
            "Train Epoch: 1 | Batch Holati: 27520/60000 (46%) | Loss: 0.255161\n",
            "Train Epoch: 1 | Batch Holati: 28160/60000 (47%) | Loss: 0.355950\n",
            "Train Epoch: 1 | Batch Holati: 28800/60000 (48%) | Loss: 0.668342\n",
            "Train Epoch: 1 | Batch Holati: 29440/60000 (49%) | Loss: 0.175057\n",
            "Train Epoch: 1 | Batch Holati: 30080/60000 (50%) | Loss: 0.224948\n",
            "Train Epoch: 1 | Batch Holati: 30720/60000 (51%) | Loss: 0.335176\n",
            "Train Epoch: 1 | Batch Holati: 31360/60000 (52%) | Loss: 0.298540\n",
            "Train Epoch: 1 | Batch Holati: 32000/60000 (53%) | Loss: 0.277401\n",
            "Train Epoch: 1 | Batch Holati: 32640/60000 (54%) | Loss: 0.326590\n",
            "Train Epoch: 1 | Batch Holati: 33280/60000 (55%) | Loss: 0.248990\n",
            "Train Epoch: 1 | Batch Holati: 33920/60000 (57%) | Loss: 0.254150\n",
            "Train Epoch: 1 | Batch Holati: 34560/60000 (58%) | Loss: 0.268000\n",
            "Train Epoch: 1 | Batch Holati: 35200/60000 (59%) | Loss: 0.425144\n",
            "Train Epoch: 1 | Batch Holati: 35840/60000 (60%) | Loss: 0.339956\n",
            "Train Epoch: 1 | Batch Holati: 36480/60000 (61%) | Loss: 0.174458\n",
            "Train Epoch: 1 | Batch Holati: 37120/60000 (62%) | Loss: 0.170803\n",
            "Train Epoch: 1 | Batch Holati: 37760/60000 (63%) | Loss: 0.184748\n",
            "Train Epoch: 1 | Batch Holati: 38400/60000 (64%) | Loss: 0.229674\n",
            "Train Epoch: 1 | Batch Holati: 39040/60000 (65%) | Loss: 0.154786\n",
            "Train Epoch: 1 | Batch Holati: 39680/60000 (66%) | Loss: 0.224630\n",
            "Train Epoch: 1 | Batch Holati: 40320/60000 (67%) | Loss: 0.313506\n",
            "Train Epoch: 1 | Batch Holati: 40960/60000 (68%) | Loss: 0.251669\n",
            "Train Epoch: 1 | Batch Holati: 41600/60000 (69%) | Loss: 0.379223\n",
            "Train Epoch: 1 | Batch Holati: 42240/60000 (70%) | Loss: 0.279835\n",
            "Train Epoch: 1 | Batch Holati: 42880/60000 (71%) | Loss: 0.163258\n",
            "Train Epoch: 1 | Batch Holati: 43520/60000 (72%) | Loss: 0.446195\n",
            "Train Epoch: 1 | Batch Holati: 44160/60000 (74%) | Loss: 0.239906\n",
            "Train Epoch: 1 | Batch Holati: 44800/60000 (75%) | Loss: 0.190687\n",
            "Train Epoch: 1 | Batch Holati: 45440/60000 (76%) | Loss: 0.199971\n",
            "Train Epoch: 1 | Batch Holati: 46080/60000 (77%) | Loss: 0.150717\n",
            "Train Epoch: 1 | Batch Holati: 46720/60000 (78%) | Loss: 0.307793\n",
            "Train Epoch: 1 | Batch Holati: 47360/60000 (79%) | Loss: 0.214178\n",
            "Train Epoch: 1 | Batch Holati: 48000/60000 (80%) | Loss: 0.263962\n",
            "Train Epoch: 1 | Batch Holati: 48640/60000 (81%) | Loss: 0.111731\n",
            "Train Epoch: 1 | Batch Holati: 49280/60000 (82%) | Loss: 0.154865\n",
            "Train Epoch: 1 | Batch Holati: 49920/60000 (83%) | Loss: 0.219407\n",
            "Train Epoch: 1 | Batch Holati: 50560/60000 (84%) | Loss: 0.161899\n",
            "Train Epoch: 1 | Batch Holati: 51200/60000 (85%) | Loss: 0.253824\n",
            "Train Epoch: 1 | Batch Holati: 51840/60000 (86%) | Loss: 0.150715\n",
            "Train Epoch: 1 | Batch Holati: 52480/60000 (87%) | Loss: 0.152738\n",
            "Train Epoch: 1 | Batch Holati: 53120/60000 (88%) | Loss: 0.166907\n",
            "Train Epoch: 1 | Batch Holati: 53760/60000 (90%) | Loss: 0.147667\n",
            "Train Epoch: 1 | Batch Holati: 54400/60000 (91%) | Loss: 0.282716\n",
            "Train Epoch: 1 | Batch Holati: 55040/60000 (92%) | Loss: 0.158647\n",
            "Train Epoch: 1 | Batch Holati: 55680/60000 (93%) | Loss: 0.271991\n",
            "Train Epoch: 1 | Batch Holati: 56320/60000 (94%) | Loss: 0.117845\n",
            "Train Epoch: 1 | Batch Holati: 56960/60000 (95%) | Loss: 0.171513\n",
            "Train Epoch: 1 | Batch Holati: 57600/60000 (96%) | Loss: 0.263126\n",
            "Train Epoch: 1 | Batch Holati: 58240/60000 (97%) | Loss: 0.185465\n",
            "Train Epoch: 1 | Batch Holati: 58880/60000 (98%) | Loss: 0.168224\n",
            "Train Epoch: 1 | Batch Holati: 59520/60000 (99%) | Loss: 0.175708\n",
            "Training uchun ketgan vaqt: 0m 17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set : Average(ortach) loss: 0.1905, Accuracy: 9408/10000 (94%)\n",
            "Test uchun ketgan vaqt: 0m 19s\n",
            "Train Epoch: 2 | Batch Holati: 0/60000 (0%) | Loss: 0.182851\n",
            "Train Epoch: 2 | Batch Holati: 640/60000 (1%) | Loss: 0.146471\n",
            "Train Epoch: 2 | Batch Holati: 1280/60000 (2%) | Loss: 0.278873\n",
            "Train Epoch: 2 | Batch Holati: 1920/60000 (3%) | Loss: 0.349332\n",
            "Train Epoch: 2 | Batch Holati: 2560/60000 (4%) | Loss: 0.155077\n",
            "Train Epoch: 2 | Batch Holati: 3200/60000 (5%) | Loss: 0.124973\n",
            "Train Epoch: 2 | Batch Holati: 3840/60000 (6%) | Loss: 0.434253\n",
            "Train Epoch: 2 | Batch Holati: 4480/60000 (7%) | Loss: 0.045001\n",
            "Train Epoch: 2 | Batch Holati: 5120/60000 (9%) | Loss: 0.097240\n",
            "Train Epoch: 2 | Batch Holati: 5760/60000 (10%) | Loss: 0.211370\n",
            "Train Epoch: 2 | Batch Holati: 6400/60000 (11%) | Loss: 0.166399\n",
            "Train Epoch: 2 | Batch Holati: 7040/60000 (12%) | Loss: 0.162570\n",
            "Train Epoch: 2 | Batch Holati: 7680/60000 (13%) | Loss: 0.102021\n",
            "Train Epoch: 2 | Batch Holati: 8320/60000 (14%) | Loss: 0.198289\n",
            "Train Epoch: 2 | Batch Holati: 8960/60000 (15%) | Loss: 0.187477\n",
            "Train Epoch: 2 | Batch Holati: 9600/60000 (16%) | Loss: 0.223659\n",
            "Train Epoch: 2 | Batch Holati: 10240/60000 (17%) | Loss: 0.212681\n",
            "Train Epoch: 2 | Batch Holati: 10880/60000 (18%) | Loss: 0.095992\n",
            "Train Epoch: 2 | Batch Holati: 11520/60000 (19%) | Loss: 0.079252\n",
            "Train Epoch: 2 | Batch Holati: 12160/60000 (20%) | Loss: 0.092541\n",
            "Train Epoch: 2 | Batch Holati: 12800/60000 (21%) | Loss: 0.516202\n",
            "Train Epoch: 2 | Batch Holati: 13440/60000 (22%) | Loss: 0.191557\n",
            "Train Epoch: 2 | Batch Holati: 14080/60000 (23%) | Loss: 0.121814\n",
            "Train Epoch: 2 | Batch Holati: 14720/60000 (25%) | Loss: 0.124084\n",
            "Train Epoch: 2 | Batch Holati: 15360/60000 (26%) | Loss: 0.096047\n",
            "Train Epoch: 2 | Batch Holati: 16000/60000 (27%) | Loss: 0.411463\n",
            "Train Epoch: 2 | Batch Holati: 16640/60000 (28%) | Loss: 0.096983\n",
            "Train Epoch: 2 | Batch Holati: 17280/60000 (29%) | Loss: 0.143121\n",
            "Train Epoch: 2 | Batch Holati: 17920/60000 (30%) | Loss: 0.270708\n",
            "Train Epoch: 2 | Batch Holati: 18560/60000 (31%) | Loss: 0.105876\n",
            "Train Epoch: 2 | Batch Holati: 19200/60000 (32%) | Loss: 0.170657\n",
            "Train Epoch: 2 | Batch Holati: 19840/60000 (33%) | Loss: 0.208864\n",
            "Train Epoch: 2 | Batch Holati: 20480/60000 (34%) | Loss: 0.051283\n",
            "Train Epoch: 2 | Batch Holati: 21120/60000 (35%) | Loss: 0.208237\n",
            "Train Epoch: 2 | Batch Holati: 21760/60000 (36%) | Loss: 0.071836\n",
            "Train Epoch: 2 | Batch Holati: 22400/60000 (37%) | Loss: 0.064420\n",
            "Train Epoch: 2 | Batch Holati: 23040/60000 (38%) | Loss: 0.382714\n",
            "Train Epoch: 2 | Batch Holati: 23680/60000 (39%) | Loss: 0.138935\n",
            "Train Epoch: 2 | Batch Holati: 24320/60000 (41%) | Loss: 0.147746\n",
            "Train Epoch: 2 | Batch Holati: 24960/60000 (42%) | Loss: 0.245223\n",
            "Train Epoch: 2 | Batch Holati: 25600/60000 (43%) | Loss: 0.137500\n",
            "Train Epoch: 2 | Batch Holati: 26240/60000 (44%) | Loss: 0.357152\n",
            "Train Epoch: 2 | Batch Holati: 26880/60000 (45%) | Loss: 0.126611\n",
            "Train Epoch: 2 | Batch Holati: 27520/60000 (46%) | Loss: 0.068845\n",
            "Train Epoch: 2 | Batch Holati: 28160/60000 (47%) | Loss: 0.105621\n",
            "Train Epoch: 2 | Batch Holati: 28800/60000 (48%) | Loss: 0.144164\n",
            "Train Epoch: 2 | Batch Holati: 29440/60000 (49%) | Loss: 0.104193\n",
            "Train Epoch: 2 | Batch Holati: 30080/60000 (50%) | Loss: 0.083995\n",
            "Train Epoch: 2 | Batch Holati: 30720/60000 (51%) | Loss: 0.280080\n",
            "Train Epoch: 2 | Batch Holati: 31360/60000 (52%) | Loss: 0.085537\n",
            "Train Epoch: 2 | Batch Holati: 32000/60000 (53%) | Loss: 0.151650\n",
            "Train Epoch: 2 | Batch Holati: 32640/60000 (54%) | Loss: 0.103499\n",
            "Train Epoch: 2 | Batch Holati: 33280/60000 (55%) | Loss: 0.192296\n",
            "Train Epoch: 2 | Batch Holati: 33920/60000 (57%) | Loss: 0.090454\n",
            "Train Epoch: 2 | Batch Holati: 34560/60000 (58%) | Loss: 0.159547\n",
            "Train Epoch: 2 | Batch Holati: 35200/60000 (59%) | Loss: 0.140663\n",
            "Train Epoch: 2 | Batch Holati: 35840/60000 (60%) | Loss: 0.103876\n",
            "Train Epoch: 2 | Batch Holati: 36480/60000 (61%) | Loss: 0.388092\n",
            "Train Epoch: 2 | Batch Holati: 37120/60000 (62%) | Loss: 0.235896\n",
            "Train Epoch: 2 | Batch Holati: 37760/60000 (63%) | Loss: 0.090162\n",
            "Train Epoch: 2 | Batch Holati: 38400/60000 (64%) | Loss: 0.179843\n",
            "Train Epoch: 2 | Batch Holati: 39040/60000 (65%) | Loss: 0.185502\n",
            "Train Epoch: 2 | Batch Holati: 39680/60000 (66%) | Loss: 0.128069\n",
            "Train Epoch: 2 | Batch Holati: 40320/60000 (67%) | Loss: 0.054842\n",
            "Train Epoch: 2 | Batch Holati: 40960/60000 (68%) | Loss: 0.131764\n",
            "Train Epoch: 2 | Batch Holati: 41600/60000 (69%) | Loss: 0.083515\n",
            "Train Epoch: 2 | Batch Holati: 42240/60000 (70%) | Loss: 0.191407\n",
            "Train Epoch: 2 | Batch Holati: 42880/60000 (71%) | Loss: 0.098635\n",
            "Train Epoch: 2 | Batch Holati: 43520/60000 (72%) | Loss: 0.070239\n",
            "Train Epoch: 2 | Batch Holati: 44160/60000 (74%) | Loss: 0.057803\n",
            "Train Epoch: 2 | Batch Holati: 44800/60000 (75%) | Loss: 0.040867\n",
            "Train Epoch: 2 | Batch Holati: 45440/60000 (76%) | Loss: 0.154246\n",
            "Train Epoch: 2 | Batch Holati: 46080/60000 (77%) | Loss: 0.078758\n",
            "Train Epoch: 2 | Batch Holati: 46720/60000 (78%) | Loss: 0.043074\n",
            "Train Epoch: 2 | Batch Holati: 47360/60000 (79%) | Loss: 0.125215\n",
            "Train Epoch: 2 | Batch Holati: 48000/60000 (80%) | Loss: 0.145481\n",
            "Train Epoch: 2 | Batch Holati: 48640/60000 (81%) | Loss: 0.118264\n",
            "Train Epoch: 2 | Batch Holati: 49280/60000 (82%) | Loss: 0.185835\n",
            "Train Epoch: 2 | Batch Holati: 49920/60000 (83%) | Loss: 0.118113\n",
            "Train Epoch: 2 | Batch Holati: 50560/60000 (84%) | Loss: 0.047116\n",
            "Train Epoch: 2 | Batch Holati: 51200/60000 (85%) | Loss: 0.377643\n",
            "Train Epoch: 2 | Batch Holati: 51840/60000 (86%) | Loss: 0.273129\n",
            "Train Epoch: 2 | Batch Holati: 52480/60000 (87%) | Loss: 0.249985\n",
            "Train Epoch: 2 | Batch Holati: 53120/60000 (88%) | Loss: 0.175123\n",
            "Train Epoch: 2 | Batch Holati: 53760/60000 (90%) | Loss: 0.114724\n",
            "Train Epoch: 2 | Batch Holati: 54400/60000 (91%) | Loss: 0.237237\n",
            "Train Epoch: 2 | Batch Holati: 55040/60000 (92%) | Loss: 0.112320\n",
            "Train Epoch: 2 | Batch Holati: 55680/60000 (93%) | Loss: 0.112937\n",
            "Train Epoch: 2 | Batch Holati: 56320/60000 (94%) | Loss: 0.120357\n",
            "Train Epoch: 2 | Batch Holati: 56960/60000 (95%) | Loss: 0.164348\n",
            "Train Epoch: 2 | Batch Holati: 57600/60000 (96%) | Loss: 0.280444\n",
            "Train Epoch: 2 | Batch Holati: 58240/60000 (97%) | Loss: 0.062376\n",
            "Train Epoch: 2 | Batch Holati: 58880/60000 (98%) | Loss: 0.219801\n",
            "Train Epoch: 2 | Batch Holati: 59520/60000 (99%) | Loss: 0.043028\n",
            "Training uchun ketgan vaqt: 0m 10s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.1108, Accuracy: 9658/10000 (97%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 3 | Batch Holati: 0/60000 (0%) | Loss: 0.137018\n",
            "Train Epoch: 3 | Batch Holati: 640/60000 (1%) | Loss: 0.148300\n",
            "Train Epoch: 3 | Batch Holati: 1280/60000 (2%) | Loss: 0.151764\n",
            "Train Epoch: 3 | Batch Holati: 1920/60000 (3%) | Loss: 0.082674\n",
            "Train Epoch: 3 | Batch Holati: 2560/60000 (4%) | Loss: 0.121746\n",
            "Train Epoch: 3 | Batch Holati: 3200/60000 (5%) | Loss: 0.120310\n",
            "Train Epoch: 3 | Batch Holati: 3840/60000 (6%) | Loss: 0.113685\n",
            "Train Epoch: 3 | Batch Holati: 4480/60000 (7%) | Loss: 0.154151\n",
            "Train Epoch: 3 | Batch Holati: 5120/60000 (9%) | Loss: 0.151876\n",
            "Train Epoch: 3 | Batch Holati: 5760/60000 (10%) | Loss: 0.076219\n",
            "Train Epoch: 3 | Batch Holati: 6400/60000 (11%) | Loss: 0.092915\n",
            "Train Epoch: 3 | Batch Holati: 7040/60000 (12%) | Loss: 0.198885\n",
            "Train Epoch: 3 | Batch Holati: 7680/60000 (13%) | Loss: 0.150547\n",
            "Train Epoch: 3 | Batch Holati: 8320/60000 (14%) | Loss: 0.128585\n",
            "Train Epoch: 3 | Batch Holati: 8960/60000 (15%) | Loss: 0.215939\n",
            "Train Epoch: 3 | Batch Holati: 9600/60000 (16%) | Loss: 0.198603\n",
            "Train Epoch: 3 | Batch Holati: 10240/60000 (17%) | Loss: 0.143703\n",
            "Train Epoch: 3 | Batch Holati: 10880/60000 (18%) | Loss: 0.134232\n",
            "Train Epoch: 3 | Batch Holati: 11520/60000 (19%) | Loss: 0.052753\n",
            "Train Epoch: 3 | Batch Holati: 12160/60000 (20%) | Loss: 0.158479\n",
            "Train Epoch: 3 | Batch Holati: 12800/60000 (21%) | Loss: 0.117522\n",
            "Train Epoch: 3 | Batch Holati: 13440/60000 (22%) | Loss: 0.051989\n",
            "Train Epoch: 3 | Batch Holati: 14080/60000 (23%) | Loss: 0.145543\n",
            "Train Epoch: 3 | Batch Holati: 14720/60000 (25%) | Loss: 0.080453\n",
            "Train Epoch: 3 | Batch Holati: 15360/60000 (26%) | Loss: 0.065094\n",
            "Train Epoch: 3 | Batch Holati: 16000/60000 (27%) | Loss: 0.107489\n",
            "Train Epoch: 3 | Batch Holati: 16640/60000 (28%) | Loss: 0.032064\n",
            "Train Epoch: 3 | Batch Holati: 17280/60000 (29%) | Loss: 0.088551\n",
            "Train Epoch: 3 | Batch Holati: 17920/60000 (30%) | Loss: 0.215093\n",
            "Train Epoch: 3 | Batch Holati: 18560/60000 (31%) | Loss: 0.108992\n",
            "Train Epoch: 3 | Batch Holati: 19200/60000 (32%) | Loss: 0.059207\n",
            "Train Epoch: 3 | Batch Holati: 19840/60000 (33%) | Loss: 0.100161\n",
            "Train Epoch: 3 | Batch Holati: 20480/60000 (34%) | Loss: 0.260648\n",
            "Train Epoch: 3 | Batch Holati: 21120/60000 (35%) | Loss: 0.218817\n",
            "Train Epoch: 3 | Batch Holati: 21760/60000 (36%) | Loss: 0.044650\n",
            "Train Epoch: 3 | Batch Holati: 22400/60000 (37%) | Loss: 0.119879\n",
            "Train Epoch: 3 | Batch Holati: 23040/60000 (38%) | Loss: 0.149414\n",
            "Train Epoch: 3 | Batch Holati: 23680/60000 (39%) | Loss: 0.259429\n",
            "Train Epoch: 3 | Batch Holati: 24320/60000 (41%) | Loss: 0.090750\n",
            "Train Epoch: 3 | Batch Holati: 24960/60000 (42%) | Loss: 0.121245\n",
            "Train Epoch: 3 | Batch Holati: 25600/60000 (43%) | Loss: 0.110573\n",
            "Train Epoch: 3 | Batch Holati: 26240/60000 (44%) | Loss: 0.088410\n",
            "Train Epoch: 3 | Batch Holati: 26880/60000 (45%) | Loss: 0.095096\n",
            "Train Epoch: 3 | Batch Holati: 27520/60000 (46%) | Loss: 0.402364\n",
            "Train Epoch: 3 | Batch Holati: 28160/60000 (47%) | Loss: 0.105604\n",
            "Train Epoch: 3 | Batch Holati: 28800/60000 (48%) | Loss: 0.060888\n",
            "Train Epoch: 3 | Batch Holati: 29440/60000 (49%) | Loss: 0.132560\n",
            "Train Epoch: 3 | Batch Holati: 30080/60000 (50%) | Loss: 0.086419\n",
            "Train Epoch: 3 | Batch Holati: 30720/60000 (51%) | Loss: 0.112262\n",
            "Train Epoch: 3 | Batch Holati: 31360/60000 (52%) | Loss: 0.084023\n",
            "Train Epoch: 3 | Batch Holati: 32000/60000 (53%) | Loss: 0.107069\n",
            "Train Epoch: 3 | Batch Holati: 32640/60000 (54%) | Loss: 0.042442\n",
            "Train Epoch: 3 | Batch Holati: 33280/60000 (55%) | Loss: 0.089971\n",
            "Train Epoch: 3 | Batch Holati: 33920/60000 (57%) | Loss: 0.139726\n",
            "Train Epoch: 3 | Batch Holati: 34560/60000 (58%) | Loss: 0.189633\n",
            "Train Epoch: 3 | Batch Holati: 35200/60000 (59%) | Loss: 0.028459\n",
            "Train Epoch: 3 | Batch Holati: 35840/60000 (60%) | Loss: 0.083787\n",
            "Train Epoch: 3 | Batch Holati: 36480/60000 (61%) | Loss: 0.292712\n",
            "Train Epoch: 3 | Batch Holati: 37120/60000 (62%) | Loss: 0.108350\n",
            "Train Epoch: 3 | Batch Holati: 37760/60000 (63%) | Loss: 0.097998\n",
            "Train Epoch: 3 | Batch Holati: 38400/60000 (64%) | Loss: 0.071032\n",
            "Train Epoch: 3 | Batch Holati: 39040/60000 (65%) | Loss: 0.039167\n",
            "Train Epoch: 3 | Batch Holati: 39680/60000 (66%) | Loss: 0.080165\n",
            "Train Epoch: 3 | Batch Holati: 40320/60000 (67%) | Loss: 0.066560\n",
            "Train Epoch: 3 | Batch Holati: 40960/60000 (68%) | Loss: 0.135914\n",
            "Train Epoch: 3 | Batch Holati: 41600/60000 (69%) | Loss: 0.094806\n",
            "Train Epoch: 3 | Batch Holati: 42240/60000 (70%) | Loss: 0.072682\n",
            "Train Epoch: 3 | Batch Holati: 42880/60000 (71%) | Loss: 0.103936\n",
            "Train Epoch: 3 | Batch Holati: 43520/60000 (72%) | Loss: 0.309262\n",
            "Train Epoch: 3 | Batch Holati: 44160/60000 (74%) | Loss: 0.197826\n",
            "Train Epoch: 3 | Batch Holati: 44800/60000 (75%) | Loss: 0.080960\n",
            "Train Epoch: 3 | Batch Holati: 45440/60000 (76%) | Loss: 0.128874\n",
            "Train Epoch: 3 | Batch Holati: 46080/60000 (77%) | Loss: 0.120238\n",
            "Train Epoch: 3 | Batch Holati: 46720/60000 (78%) | Loss: 0.060083\n",
            "Train Epoch: 3 | Batch Holati: 47360/60000 (79%) | Loss: 0.187592\n",
            "Train Epoch: 3 | Batch Holati: 48000/60000 (80%) | Loss: 0.054673\n",
            "Train Epoch: 3 | Batch Holati: 48640/60000 (81%) | Loss: 0.140908\n",
            "Train Epoch: 3 | Batch Holati: 49280/60000 (82%) | Loss: 0.024170\n",
            "Train Epoch: 3 | Batch Holati: 49920/60000 (83%) | Loss: 0.044220\n",
            "Train Epoch: 3 | Batch Holati: 50560/60000 (84%) | Loss: 0.137603\n",
            "Train Epoch: 3 | Batch Holati: 51200/60000 (85%) | Loss: 0.093329\n",
            "Train Epoch: 3 | Batch Holati: 51840/60000 (86%) | Loss: 0.067986\n",
            "Train Epoch: 3 | Batch Holati: 52480/60000 (87%) | Loss: 0.027931\n",
            "Train Epoch: 3 | Batch Holati: 53120/60000 (88%) | Loss: 0.033549\n",
            "Train Epoch: 3 | Batch Holati: 53760/60000 (90%) | Loss: 0.132234\n",
            "Train Epoch: 3 | Batch Holati: 54400/60000 (91%) | Loss: 0.102558\n",
            "Train Epoch: 3 | Batch Holati: 55040/60000 (92%) | Loss: 0.114216\n",
            "Train Epoch: 3 | Batch Holati: 55680/60000 (93%) | Loss: 0.069117\n",
            "Train Epoch: 3 | Batch Holati: 56320/60000 (94%) | Loss: 0.164254\n",
            "Train Epoch: 3 | Batch Holati: 56960/60000 (95%) | Loss: 0.028035\n",
            "Train Epoch: 3 | Batch Holati: 57600/60000 (96%) | Loss: 0.145605\n",
            "Train Epoch: 3 | Batch Holati: 58240/60000 (97%) | Loss: 0.199926\n",
            "Train Epoch: 3 | Batch Holati: 58880/60000 (98%) | Loss: 0.110186\n",
            "Train Epoch: 3 | Batch Holati: 59520/60000 (99%) | Loss: 0.185560\n",
            "Training uchun ketgan vaqt: 0m 10s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0893, Accuracy: 9731/10000 (97%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 4 | Batch Holati: 0/60000 (0%) | Loss: 0.098657\n",
            "Train Epoch: 4 | Batch Holati: 640/60000 (1%) | Loss: 0.123045\n",
            "Train Epoch: 4 | Batch Holati: 1280/60000 (2%) | Loss: 0.079407\n",
            "Train Epoch: 4 | Batch Holati: 1920/60000 (3%) | Loss: 0.610952\n",
            "Train Epoch: 4 | Batch Holati: 2560/60000 (4%) | Loss: 0.044209\n",
            "Train Epoch: 4 | Batch Holati: 3200/60000 (5%) | Loss: 0.179527\n",
            "Train Epoch: 4 | Batch Holati: 3840/60000 (6%) | Loss: 0.173829\n",
            "Train Epoch: 4 | Batch Holati: 4480/60000 (7%) | Loss: 0.190827\n",
            "Train Epoch: 4 | Batch Holati: 5120/60000 (9%) | Loss: 0.177718\n",
            "Train Epoch: 4 | Batch Holati: 5760/60000 (10%) | Loss: 0.090803\n",
            "Train Epoch: 4 | Batch Holati: 6400/60000 (11%) | Loss: 0.066004\n",
            "Train Epoch: 4 | Batch Holati: 7040/60000 (12%) | Loss: 0.108294\n",
            "Train Epoch: 4 | Batch Holati: 7680/60000 (13%) | Loss: 0.025206\n",
            "Train Epoch: 4 | Batch Holati: 8320/60000 (14%) | Loss: 0.063410\n",
            "Train Epoch: 4 | Batch Holati: 8960/60000 (15%) | Loss: 0.084842\n",
            "Train Epoch: 4 | Batch Holati: 9600/60000 (16%) | Loss: 0.149496\n",
            "Train Epoch: 4 | Batch Holati: 10240/60000 (17%) | Loss: 0.093038\n",
            "Train Epoch: 4 | Batch Holati: 10880/60000 (18%) | Loss: 0.042158\n",
            "Train Epoch: 4 | Batch Holati: 11520/60000 (19%) | Loss: 0.334817\n",
            "Train Epoch: 4 | Batch Holati: 12160/60000 (20%) | Loss: 0.055288\n",
            "Train Epoch: 4 | Batch Holati: 12800/60000 (21%) | Loss: 0.070255\n",
            "Train Epoch: 4 | Batch Holati: 13440/60000 (22%) | Loss: 0.093645\n",
            "Train Epoch: 4 | Batch Holati: 14080/60000 (23%) | Loss: 0.050702\n",
            "Train Epoch: 4 | Batch Holati: 14720/60000 (25%) | Loss: 0.148774\n",
            "Train Epoch: 4 | Batch Holati: 15360/60000 (26%) | Loss: 0.048619\n",
            "Train Epoch: 4 | Batch Holati: 16000/60000 (27%) | Loss: 0.042619\n",
            "Train Epoch: 4 | Batch Holati: 16640/60000 (28%) | Loss: 0.067429\n",
            "Train Epoch: 4 | Batch Holati: 17280/60000 (29%) | Loss: 0.042693\n",
            "Train Epoch: 4 | Batch Holati: 17920/60000 (30%) | Loss: 0.053728\n",
            "Train Epoch: 4 | Batch Holati: 18560/60000 (31%) | Loss: 0.150574\n",
            "Train Epoch: 4 | Batch Holati: 19200/60000 (32%) | Loss: 0.151764\n",
            "Train Epoch: 4 | Batch Holati: 19840/60000 (33%) | Loss: 0.059573\n",
            "Train Epoch: 4 | Batch Holati: 20480/60000 (34%) | Loss: 0.036726\n",
            "Train Epoch: 4 | Batch Holati: 21120/60000 (35%) | Loss: 0.044461\n",
            "Train Epoch: 4 | Batch Holati: 21760/60000 (36%) | Loss: 0.121129\n",
            "Train Epoch: 4 | Batch Holati: 22400/60000 (37%) | Loss: 0.062231\n",
            "Train Epoch: 4 | Batch Holati: 23040/60000 (38%) | Loss: 0.137142\n",
            "Train Epoch: 4 | Batch Holati: 23680/60000 (39%) | Loss: 0.044708\n",
            "Train Epoch: 4 | Batch Holati: 24320/60000 (41%) | Loss: 0.079204\n",
            "Train Epoch: 4 | Batch Holati: 24960/60000 (42%) | Loss: 0.167147\n",
            "Train Epoch: 4 | Batch Holati: 25600/60000 (43%) | Loss: 0.076975\n",
            "Train Epoch: 4 | Batch Holati: 26240/60000 (44%) | Loss: 0.087370\n",
            "Train Epoch: 4 | Batch Holati: 26880/60000 (45%) | Loss: 0.165924\n",
            "Train Epoch: 4 | Batch Holati: 27520/60000 (46%) | Loss: 0.142110\n",
            "Train Epoch: 4 | Batch Holati: 28160/60000 (47%) | Loss: 0.108797\n",
            "Train Epoch: 4 | Batch Holati: 28800/60000 (48%) | Loss: 0.040171\n",
            "Train Epoch: 4 | Batch Holati: 29440/60000 (49%) | Loss: 0.087710\n",
            "Train Epoch: 4 | Batch Holati: 30080/60000 (50%) | Loss: 0.043780\n",
            "Train Epoch: 4 | Batch Holati: 30720/60000 (51%) | Loss: 0.028789\n",
            "Train Epoch: 4 | Batch Holati: 31360/60000 (52%) | Loss: 0.143327\n",
            "Train Epoch: 4 | Batch Holati: 32000/60000 (53%) | Loss: 0.142439\n",
            "Train Epoch: 4 | Batch Holati: 32640/60000 (54%) | Loss: 0.027380\n",
            "Train Epoch: 4 | Batch Holati: 33280/60000 (55%) | Loss: 0.060625\n",
            "Train Epoch: 4 | Batch Holati: 33920/60000 (57%) | Loss: 0.059920\n",
            "Train Epoch: 4 | Batch Holati: 34560/60000 (58%) | Loss: 0.059646\n",
            "Train Epoch: 4 | Batch Holati: 35200/60000 (59%) | Loss: 0.065971\n",
            "Train Epoch: 4 | Batch Holati: 35840/60000 (60%) | Loss: 0.150593\n",
            "Train Epoch: 4 | Batch Holati: 36480/60000 (61%) | Loss: 0.062356\n",
            "Train Epoch: 4 | Batch Holati: 37120/60000 (62%) | Loss: 0.210756\n",
            "Train Epoch: 4 | Batch Holati: 37760/60000 (63%) | Loss: 0.081514\n",
            "Train Epoch: 4 | Batch Holati: 38400/60000 (64%) | Loss: 0.154442\n",
            "Train Epoch: 4 | Batch Holati: 39040/60000 (65%) | Loss: 0.039242\n",
            "Train Epoch: 4 | Batch Holati: 39680/60000 (66%) | Loss: 0.083114\n",
            "Train Epoch: 4 | Batch Holati: 40320/60000 (67%) | Loss: 0.026207\n",
            "Train Epoch: 4 | Batch Holati: 40960/60000 (68%) | Loss: 0.076249\n",
            "Train Epoch: 4 | Batch Holati: 41600/60000 (69%) | Loss: 0.083720\n",
            "Train Epoch: 4 | Batch Holati: 42240/60000 (70%) | Loss: 0.093067\n",
            "Train Epoch: 4 | Batch Holati: 42880/60000 (71%) | Loss: 0.041710\n",
            "Train Epoch: 4 | Batch Holati: 43520/60000 (72%) | Loss: 0.020860\n",
            "Train Epoch: 4 | Batch Holati: 44160/60000 (74%) | Loss: 0.039585\n",
            "Train Epoch: 4 | Batch Holati: 44800/60000 (75%) | Loss: 0.125252\n",
            "Train Epoch: 4 | Batch Holati: 45440/60000 (76%) | Loss: 0.188620\n",
            "Train Epoch: 4 | Batch Holati: 46080/60000 (77%) | Loss: 0.071033\n",
            "Train Epoch: 4 | Batch Holati: 46720/60000 (78%) | Loss: 0.021909\n",
            "Train Epoch: 4 | Batch Holati: 47360/60000 (79%) | Loss: 0.045408\n",
            "Train Epoch: 4 | Batch Holati: 48000/60000 (80%) | Loss: 0.104189\n",
            "Train Epoch: 4 | Batch Holati: 48640/60000 (81%) | Loss: 0.155909\n",
            "Train Epoch: 4 | Batch Holati: 49280/60000 (82%) | Loss: 0.142287\n",
            "Train Epoch: 4 | Batch Holati: 49920/60000 (83%) | Loss: 0.042874\n",
            "Train Epoch: 4 | Batch Holati: 50560/60000 (84%) | Loss: 0.065921\n",
            "Train Epoch: 4 | Batch Holati: 51200/60000 (85%) | Loss: 0.066394\n",
            "Train Epoch: 4 | Batch Holati: 51840/60000 (86%) | Loss: 0.115488\n",
            "Train Epoch: 4 | Batch Holati: 52480/60000 (87%) | Loss: 0.134226\n",
            "Train Epoch: 4 | Batch Holati: 53120/60000 (88%) | Loss: 0.076634\n",
            "Train Epoch: 4 | Batch Holati: 53760/60000 (90%) | Loss: 0.074204\n",
            "Train Epoch: 4 | Batch Holati: 54400/60000 (91%) | Loss: 0.089001\n",
            "Train Epoch: 4 | Batch Holati: 55040/60000 (92%) | Loss: 0.027019\n",
            "Train Epoch: 4 | Batch Holati: 55680/60000 (93%) | Loss: 0.066547\n",
            "Train Epoch: 4 | Batch Holati: 56320/60000 (94%) | Loss: 0.150111\n",
            "Train Epoch: 4 | Batch Holati: 56960/60000 (95%) | Loss: 0.154543\n",
            "Train Epoch: 4 | Batch Holati: 57600/60000 (96%) | Loss: 0.078608\n",
            "Train Epoch: 4 | Batch Holati: 58240/60000 (97%) | Loss: 0.152646\n",
            "Train Epoch: 4 | Batch Holati: 58880/60000 (98%) | Loss: 0.075917\n",
            "Train Epoch: 4 | Batch Holati: 59520/60000 (99%) | Loss: 0.128559\n",
            "Training uchun ketgan vaqt: 0m 10s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0760, Accuracy: 9768/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 5 | Batch Holati: 0/60000 (0%) | Loss: 0.102869\n",
            "Train Epoch: 5 | Batch Holati: 640/60000 (1%) | Loss: 0.260784\n",
            "Train Epoch: 5 | Batch Holati: 1280/60000 (2%) | Loss: 0.062855\n",
            "Train Epoch: 5 | Batch Holati: 1920/60000 (3%) | Loss: 0.093879\n",
            "Train Epoch: 5 | Batch Holati: 2560/60000 (4%) | Loss: 0.179994\n",
            "Train Epoch: 5 | Batch Holati: 3200/60000 (5%) | Loss: 0.069799\n",
            "Train Epoch: 5 | Batch Holati: 3840/60000 (6%) | Loss: 0.141313\n",
            "Train Epoch: 5 | Batch Holati: 4480/60000 (7%) | Loss: 0.021193\n",
            "Train Epoch: 5 | Batch Holati: 5120/60000 (9%) | Loss: 0.163120\n",
            "Train Epoch: 5 | Batch Holati: 5760/60000 (10%) | Loss: 0.085288\n",
            "Train Epoch: 5 | Batch Holati: 6400/60000 (11%) | Loss: 0.225392\n",
            "Train Epoch: 5 | Batch Holati: 7040/60000 (12%) | Loss: 0.072232\n",
            "Train Epoch: 5 | Batch Holati: 7680/60000 (13%) | Loss: 0.032201\n",
            "Train Epoch: 5 | Batch Holati: 8320/60000 (14%) | Loss: 0.026635\n",
            "Train Epoch: 5 | Batch Holati: 8960/60000 (15%) | Loss: 0.171128\n",
            "Train Epoch: 5 | Batch Holati: 9600/60000 (16%) | Loss: 0.047180\n",
            "Train Epoch: 5 | Batch Holati: 10240/60000 (17%) | Loss: 0.071562\n",
            "Train Epoch: 5 | Batch Holati: 10880/60000 (18%) | Loss: 0.069397\n",
            "Train Epoch: 5 | Batch Holati: 11520/60000 (19%) | Loss: 0.173395\n",
            "Train Epoch: 5 | Batch Holati: 12160/60000 (20%) | Loss: 0.060117\n",
            "Train Epoch: 5 | Batch Holati: 12800/60000 (21%) | Loss: 0.050710\n",
            "Train Epoch: 5 | Batch Holati: 13440/60000 (22%) | Loss: 0.039790\n",
            "Train Epoch: 5 | Batch Holati: 14080/60000 (23%) | Loss: 0.102588\n",
            "Train Epoch: 5 | Batch Holati: 14720/60000 (25%) | Loss: 0.040852\n",
            "Train Epoch: 5 | Batch Holati: 15360/60000 (26%) | Loss: 0.093125\n",
            "Train Epoch: 5 | Batch Holati: 16000/60000 (27%) | Loss: 0.046880\n",
            "Train Epoch: 5 | Batch Holati: 16640/60000 (28%) | Loss: 0.037326\n",
            "Train Epoch: 5 | Batch Holati: 17280/60000 (29%) | Loss: 0.155773\n",
            "Train Epoch: 5 | Batch Holati: 17920/60000 (30%) | Loss: 0.078348\n",
            "Train Epoch: 5 | Batch Holati: 18560/60000 (31%) | Loss: 0.173924\n",
            "Train Epoch: 5 | Batch Holati: 19200/60000 (32%) | Loss: 0.083007\n",
            "Train Epoch: 5 | Batch Holati: 19840/60000 (33%) | Loss: 0.102164\n",
            "Train Epoch: 5 | Batch Holati: 20480/60000 (34%) | Loss: 0.042876\n",
            "Train Epoch: 5 | Batch Holati: 21120/60000 (35%) | Loss: 0.012621\n",
            "Train Epoch: 5 | Batch Holati: 21760/60000 (36%) | Loss: 0.230274\n",
            "Train Epoch: 5 | Batch Holati: 22400/60000 (37%) | Loss: 0.114209\n",
            "Train Epoch: 5 | Batch Holati: 23040/60000 (38%) | Loss: 0.119091\n",
            "Train Epoch: 5 | Batch Holati: 23680/60000 (39%) | Loss: 0.044599\n",
            "Train Epoch: 5 | Batch Holati: 24320/60000 (41%) | Loss: 0.025835\n",
            "Train Epoch: 5 | Batch Holati: 24960/60000 (42%) | Loss: 0.126918\n",
            "Train Epoch: 5 | Batch Holati: 25600/60000 (43%) | Loss: 0.027903\n",
            "Train Epoch: 5 | Batch Holati: 26240/60000 (44%) | Loss: 0.043430\n",
            "Train Epoch: 5 | Batch Holati: 26880/60000 (45%) | Loss: 0.047149\n",
            "Train Epoch: 5 | Batch Holati: 27520/60000 (46%) | Loss: 0.075646\n",
            "Train Epoch: 5 | Batch Holati: 28160/60000 (47%) | Loss: 0.104320\n",
            "Train Epoch: 5 | Batch Holati: 28800/60000 (48%) | Loss: 0.048057\n",
            "Train Epoch: 5 | Batch Holati: 29440/60000 (49%) | Loss: 0.080277\n",
            "Train Epoch: 5 | Batch Holati: 30080/60000 (50%) | Loss: 0.056113\n",
            "Train Epoch: 5 | Batch Holati: 30720/60000 (51%) | Loss: 0.091105\n",
            "Train Epoch: 5 | Batch Holati: 31360/60000 (52%) | Loss: 0.127816\n",
            "Train Epoch: 5 | Batch Holati: 32000/60000 (53%) | Loss: 0.130400\n",
            "Train Epoch: 5 | Batch Holati: 32640/60000 (54%) | Loss: 0.117954\n",
            "Train Epoch: 5 | Batch Holati: 33280/60000 (55%) | Loss: 0.059406\n",
            "Train Epoch: 5 | Batch Holati: 33920/60000 (57%) | Loss: 0.168359\n",
            "Train Epoch: 5 | Batch Holati: 34560/60000 (58%) | Loss: 0.039901\n",
            "Train Epoch: 5 | Batch Holati: 35200/60000 (59%) | Loss: 0.096011\n",
            "Train Epoch: 5 | Batch Holati: 35840/60000 (60%) | Loss: 0.058530\n",
            "Train Epoch: 5 | Batch Holati: 36480/60000 (61%) | Loss: 0.035775\n",
            "Train Epoch: 5 | Batch Holati: 37120/60000 (62%) | Loss: 0.027332\n",
            "Train Epoch: 5 | Batch Holati: 37760/60000 (63%) | Loss: 0.085374\n",
            "Train Epoch: 5 | Batch Holati: 38400/60000 (64%) | Loss: 0.146981\n",
            "Train Epoch: 5 | Batch Holati: 39040/60000 (65%) | Loss: 0.183354\n",
            "Train Epoch: 5 | Batch Holati: 39680/60000 (66%) | Loss: 0.038590\n",
            "Train Epoch: 5 | Batch Holati: 40320/60000 (67%) | Loss: 0.033713\n",
            "Train Epoch: 5 | Batch Holati: 40960/60000 (68%) | Loss: 0.029739\n",
            "Train Epoch: 5 | Batch Holati: 41600/60000 (69%) | Loss: 0.026163\n",
            "Train Epoch: 5 | Batch Holati: 42240/60000 (70%) | Loss: 0.043894\n",
            "Train Epoch: 5 | Batch Holati: 42880/60000 (71%) | Loss: 0.036258\n",
            "Train Epoch: 5 | Batch Holati: 43520/60000 (72%) | Loss: 0.162220\n",
            "Train Epoch: 5 | Batch Holati: 44160/60000 (74%) | Loss: 0.152814\n",
            "Train Epoch: 5 | Batch Holati: 44800/60000 (75%) | Loss: 0.111616\n",
            "Train Epoch: 5 | Batch Holati: 45440/60000 (76%) | Loss: 0.063582\n",
            "Train Epoch: 5 | Batch Holati: 46080/60000 (77%) | Loss: 0.049338\n",
            "Train Epoch: 5 | Batch Holati: 46720/60000 (78%) | Loss: 0.055192\n",
            "Train Epoch: 5 | Batch Holati: 47360/60000 (79%) | Loss: 0.093626\n",
            "Train Epoch: 5 | Batch Holati: 48000/60000 (80%) | Loss: 0.042243\n",
            "Train Epoch: 5 | Batch Holati: 48640/60000 (81%) | Loss: 0.040632\n",
            "Train Epoch: 5 | Batch Holati: 49280/60000 (82%) | Loss: 0.041880\n",
            "Train Epoch: 5 | Batch Holati: 49920/60000 (83%) | Loss: 0.107082\n",
            "Train Epoch: 5 | Batch Holati: 50560/60000 (84%) | Loss: 0.029924\n",
            "Train Epoch: 5 | Batch Holati: 51200/60000 (85%) | Loss: 0.052245\n",
            "Train Epoch: 5 | Batch Holati: 51840/60000 (86%) | Loss: 0.039132\n",
            "Train Epoch: 5 | Batch Holati: 52480/60000 (87%) | Loss: 0.061652\n",
            "Train Epoch: 5 | Batch Holati: 53120/60000 (88%) | Loss: 0.062704\n",
            "Train Epoch: 5 | Batch Holati: 53760/60000 (90%) | Loss: 0.111658\n",
            "Train Epoch: 5 | Batch Holati: 54400/60000 (91%) | Loss: 0.058443\n",
            "Train Epoch: 5 | Batch Holati: 55040/60000 (92%) | Loss: 0.022595\n",
            "Train Epoch: 5 | Batch Holati: 55680/60000 (93%) | Loss: 0.110490\n",
            "Train Epoch: 5 | Batch Holati: 56320/60000 (94%) | Loss: 0.051880\n",
            "Train Epoch: 5 | Batch Holati: 56960/60000 (95%) | Loss: 0.147545\n",
            "Train Epoch: 5 | Batch Holati: 57600/60000 (96%) | Loss: 0.026743\n",
            "Train Epoch: 5 | Batch Holati: 58240/60000 (97%) | Loss: 0.049672\n",
            "Train Epoch: 5 | Batch Holati: 58880/60000 (98%) | Loss: 0.287255\n",
            "Train Epoch: 5 | Batch Holati: 59520/60000 (99%) | Loss: 0.194097\n",
            "Training uchun ketgan vaqt: 0m 10s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0663, Accuracy: 9792/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 12s\n",
            "Train Epoch: 6 | Batch Holati: 0/60000 (0%) | Loss: 0.103443\n",
            "Train Epoch: 6 | Batch Holati: 640/60000 (1%) | Loss: 0.057904\n",
            "Train Epoch: 6 | Batch Holati: 1280/60000 (2%) | Loss: 0.158422\n",
            "Train Epoch: 6 | Batch Holati: 1920/60000 (3%) | Loss: 0.047007\n",
            "Train Epoch: 6 | Batch Holati: 2560/60000 (4%) | Loss: 0.063541\n",
            "Train Epoch: 6 | Batch Holati: 3200/60000 (5%) | Loss: 0.010902\n",
            "Train Epoch: 6 | Batch Holati: 3840/60000 (6%) | Loss: 0.095556\n",
            "Train Epoch: 6 | Batch Holati: 4480/60000 (7%) | Loss: 0.013990\n",
            "Train Epoch: 6 | Batch Holati: 5120/60000 (9%) | Loss: 0.059112\n",
            "Train Epoch: 6 | Batch Holati: 5760/60000 (10%) | Loss: 0.069035\n",
            "Train Epoch: 6 | Batch Holati: 6400/60000 (11%) | Loss: 0.098426\n",
            "Train Epoch: 6 | Batch Holati: 7040/60000 (12%) | Loss: 0.037885\n",
            "Train Epoch: 6 | Batch Holati: 7680/60000 (13%) | Loss: 0.027632\n",
            "Train Epoch: 6 | Batch Holati: 8320/60000 (14%) | Loss: 0.206167\n",
            "Train Epoch: 6 | Batch Holati: 8960/60000 (15%) | Loss: 0.056179\n",
            "Train Epoch: 6 | Batch Holati: 9600/60000 (16%) | Loss: 0.096047\n",
            "Train Epoch: 6 | Batch Holati: 10240/60000 (17%) | Loss: 0.057044\n",
            "Train Epoch: 6 | Batch Holati: 10880/60000 (18%) | Loss: 0.168947\n",
            "Train Epoch: 6 | Batch Holati: 11520/60000 (19%) | Loss: 0.031220\n",
            "Train Epoch: 6 | Batch Holati: 12160/60000 (20%) | Loss: 0.040815\n",
            "Train Epoch: 6 | Batch Holati: 12800/60000 (21%) | Loss: 0.028497\n",
            "Train Epoch: 6 | Batch Holati: 13440/60000 (22%) | Loss: 0.101924\n",
            "Train Epoch: 6 | Batch Holati: 14080/60000 (23%) | Loss: 0.154092\n",
            "Train Epoch: 6 | Batch Holati: 14720/60000 (25%) | Loss: 0.020690\n",
            "Train Epoch: 6 | Batch Holati: 15360/60000 (26%) | Loss: 0.102118\n",
            "Train Epoch: 6 | Batch Holati: 16000/60000 (27%) | Loss: 0.052110\n",
            "Train Epoch: 6 | Batch Holati: 16640/60000 (28%) | Loss: 0.105673\n",
            "Train Epoch: 6 | Batch Holati: 17280/60000 (29%) | Loss: 0.147240\n",
            "Train Epoch: 6 | Batch Holati: 17920/60000 (30%) | Loss: 0.075322\n",
            "Train Epoch: 6 | Batch Holati: 18560/60000 (31%) | Loss: 0.139130\n",
            "Train Epoch: 6 | Batch Holati: 19200/60000 (32%) | Loss: 0.079863\n",
            "Train Epoch: 6 | Batch Holati: 19840/60000 (33%) | Loss: 0.034511\n",
            "Train Epoch: 6 | Batch Holati: 20480/60000 (34%) | Loss: 0.069019\n",
            "Train Epoch: 6 | Batch Holati: 21120/60000 (35%) | Loss: 0.127216\n",
            "Train Epoch: 6 | Batch Holati: 21760/60000 (36%) | Loss: 0.014202\n",
            "Train Epoch: 6 | Batch Holati: 22400/60000 (37%) | Loss: 0.031954\n",
            "Train Epoch: 6 | Batch Holati: 23040/60000 (38%) | Loss: 0.038306\n",
            "Train Epoch: 6 | Batch Holati: 23680/60000 (39%) | Loss: 0.083557\n",
            "Train Epoch: 6 | Batch Holati: 24320/60000 (41%) | Loss: 0.031598\n",
            "Train Epoch: 6 | Batch Holati: 24960/60000 (42%) | Loss: 0.041713\n",
            "Train Epoch: 6 | Batch Holati: 25600/60000 (43%) | Loss: 0.021209\n",
            "Train Epoch: 6 | Batch Holati: 26240/60000 (44%) | Loss: 0.014802\n",
            "Train Epoch: 6 | Batch Holati: 26880/60000 (45%) | Loss: 0.084240\n",
            "Train Epoch: 6 | Batch Holati: 27520/60000 (46%) | Loss: 0.045521\n",
            "Train Epoch: 6 | Batch Holati: 28160/60000 (47%) | Loss: 0.093317\n",
            "Train Epoch: 6 | Batch Holati: 28800/60000 (48%) | Loss: 0.023445\n",
            "Train Epoch: 6 | Batch Holati: 29440/60000 (49%) | Loss: 0.054173\n",
            "Train Epoch: 6 | Batch Holati: 30080/60000 (50%) | Loss: 0.094416\n",
            "Train Epoch: 6 | Batch Holati: 30720/60000 (51%) | Loss: 0.063883\n",
            "Train Epoch: 6 | Batch Holati: 31360/60000 (52%) | Loss: 0.032368\n",
            "Train Epoch: 6 | Batch Holati: 32000/60000 (53%) | Loss: 0.135363\n",
            "Train Epoch: 6 | Batch Holati: 32640/60000 (54%) | Loss: 0.048635\n",
            "Train Epoch: 6 | Batch Holati: 33280/60000 (55%) | Loss: 0.093437\n",
            "Train Epoch: 6 | Batch Holati: 33920/60000 (57%) | Loss: 0.077294\n",
            "Train Epoch: 6 | Batch Holati: 34560/60000 (58%) | Loss: 0.061525\n",
            "Train Epoch: 6 | Batch Holati: 35200/60000 (59%) | Loss: 0.043092\n",
            "Train Epoch: 6 | Batch Holati: 35840/60000 (60%) | Loss: 0.094278\n",
            "Train Epoch: 6 | Batch Holati: 36480/60000 (61%) | Loss: 0.115386\n",
            "Train Epoch: 6 | Batch Holati: 37120/60000 (62%) | Loss: 0.081983\n",
            "Train Epoch: 6 | Batch Holati: 37760/60000 (63%) | Loss: 0.109562\n",
            "Train Epoch: 6 | Batch Holati: 38400/60000 (64%) | Loss: 0.263966\n",
            "Train Epoch: 6 | Batch Holati: 39040/60000 (65%) | Loss: 0.023142\n",
            "Train Epoch: 6 | Batch Holati: 39680/60000 (66%) | Loss: 0.011378\n",
            "Train Epoch: 6 | Batch Holati: 40320/60000 (67%) | Loss: 0.015015\n",
            "Train Epoch: 6 | Batch Holati: 40960/60000 (68%) | Loss: 0.066218\n",
            "Train Epoch: 6 | Batch Holati: 41600/60000 (69%) | Loss: 0.144689\n",
            "Train Epoch: 6 | Batch Holati: 42240/60000 (70%) | Loss: 0.069477\n",
            "Train Epoch: 6 | Batch Holati: 42880/60000 (71%) | Loss: 0.092764\n",
            "Train Epoch: 6 | Batch Holati: 43520/60000 (72%) | Loss: 0.056432\n",
            "Train Epoch: 6 | Batch Holati: 44160/60000 (74%) | Loss: 0.039559\n",
            "Train Epoch: 6 | Batch Holati: 44800/60000 (75%) | Loss: 0.020317\n",
            "Train Epoch: 6 | Batch Holati: 45440/60000 (76%) | Loss: 0.036028\n",
            "Train Epoch: 6 | Batch Holati: 46080/60000 (77%) | Loss: 0.163476\n",
            "Train Epoch: 6 | Batch Holati: 46720/60000 (78%) | Loss: 0.036828\n",
            "Train Epoch: 6 | Batch Holati: 47360/60000 (79%) | Loss: 0.127676\n",
            "Train Epoch: 6 | Batch Holati: 48000/60000 (80%) | Loss: 0.065809\n",
            "Train Epoch: 6 | Batch Holati: 48640/60000 (81%) | Loss: 0.077156\n",
            "Train Epoch: 6 | Batch Holati: 49280/60000 (82%) | Loss: 0.019525\n",
            "Train Epoch: 6 | Batch Holati: 49920/60000 (83%) | Loss: 0.046668\n",
            "Train Epoch: 6 | Batch Holati: 50560/60000 (84%) | Loss: 0.073251\n",
            "Train Epoch: 6 | Batch Holati: 51200/60000 (85%) | Loss: 0.053445\n",
            "Train Epoch: 6 | Batch Holati: 51840/60000 (86%) | Loss: 0.027863\n",
            "Train Epoch: 6 | Batch Holati: 52480/60000 (87%) | Loss: 0.014577\n",
            "Train Epoch: 6 | Batch Holati: 53120/60000 (88%) | Loss: 0.025089\n",
            "Train Epoch: 6 | Batch Holati: 53760/60000 (90%) | Loss: 0.014549\n",
            "Train Epoch: 6 | Batch Holati: 54400/60000 (91%) | Loss: 0.036480\n",
            "Train Epoch: 6 | Batch Holati: 55040/60000 (92%) | Loss: 0.072234\n",
            "Train Epoch: 6 | Batch Holati: 55680/60000 (93%) | Loss: 0.160056\n",
            "Train Epoch: 6 | Batch Holati: 56320/60000 (94%) | Loss: 0.110964\n",
            "Train Epoch: 6 | Batch Holati: 56960/60000 (95%) | Loss: 0.106825\n",
            "Train Epoch: 6 | Batch Holati: 57600/60000 (96%) | Loss: 0.066799\n",
            "Train Epoch: 6 | Batch Holati: 58240/60000 (97%) | Loss: 0.047779\n",
            "Train Epoch: 6 | Batch Holati: 58880/60000 (98%) | Loss: 0.081349\n",
            "Train Epoch: 6 | Batch Holati: 59520/60000 (99%) | Loss: 0.042964\n",
            "Training uchun ketgan vaqt: 0m 9s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0593, Accuracy: 9824/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 7 | Batch Holati: 0/60000 (0%) | Loss: 0.036612\n",
            "Train Epoch: 7 | Batch Holati: 640/60000 (1%) | Loss: 0.058416\n",
            "Train Epoch: 7 | Batch Holati: 1280/60000 (2%) | Loss: 0.025257\n",
            "Train Epoch: 7 | Batch Holati: 1920/60000 (3%) | Loss: 0.106963\n",
            "Train Epoch: 7 | Batch Holati: 2560/60000 (4%) | Loss: 0.055542\n",
            "Train Epoch: 7 | Batch Holati: 3200/60000 (5%) | Loss: 0.030883\n",
            "Train Epoch: 7 | Batch Holati: 3840/60000 (6%) | Loss: 0.010433\n",
            "Train Epoch: 7 | Batch Holati: 4480/60000 (7%) | Loss: 0.029683\n",
            "Train Epoch: 7 | Batch Holati: 5120/60000 (9%) | Loss: 0.127154\n",
            "Train Epoch: 7 | Batch Holati: 5760/60000 (10%) | Loss: 0.034117\n",
            "Train Epoch: 7 | Batch Holati: 6400/60000 (11%) | Loss: 0.026376\n",
            "Train Epoch: 7 | Batch Holati: 7040/60000 (12%) | Loss: 0.011796\n",
            "Train Epoch: 7 | Batch Holati: 7680/60000 (13%) | Loss: 0.100920\n",
            "Train Epoch: 7 | Batch Holati: 8320/60000 (14%) | Loss: 0.058764\n",
            "Train Epoch: 7 | Batch Holati: 8960/60000 (15%) | Loss: 0.034463\n",
            "Train Epoch: 7 | Batch Holati: 9600/60000 (16%) | Loss: 0.026323\n",
            "Train Epoch: 7 | Batch Holati: 10240/60000 (17%) | Loss: 0.028154\n",
            "Train Epoch: 7 | Batch Holati: 10880/60000 (18%) | Loss: 0.113149\n",
            "Train Epoch: 7 | Batch Holati: 11520/60000 (19%) | Loss: 0.044360\n",
            "Train Epoch: 7 | Batch Holati: 12160/60000 (20%) | Loss: 0.009805\n",
            "Train Epoch: 7 | Batch Holati: 12800/60000 (21%) | Loss: 0.034637\n",
            "Train Epoch: 7 | Batch Holati: 13440/60000 (22%) | Loss: 0.032788\n",
            "Train Epoch: 7 | Batch Holati: 14080/60000 (23%) | Loss: 0.022233\n",
            "Train Epoch: 7 | Batch Holati: 14720/60000 (25%) | Loss: 0.062686\n",
            "Train Epoch: 7 | Batch Holati: 15360/60000 (26%) | Loss: 0.033519\n",
            "Train Epoch: 7 | Batch Holati: 16000/60000 (27%) | Loss: 0.078877\n",
            "Train Epoch: 7 | Batch Holati: 16640/60000 (28%) | Loss: 0.060637\n",
            "Train Epoch: 7 | Batch Holati: 17280/60000 (29%) | Loss: 0.130620\n",
            "Train Epoch: 7 | Batch Holati: 17920/60000 (30%) | Loss: 0.024372\n",
            "Train Epoch: 7 | Batch Holati: 18560/60000 (31%) | Loss: 0.072552\n",
            "Train Epoch: 7 | Batch Holati: 19200/60000 (32%) | Loss: 0.035393\n",
            "Train Epoch: 7 | Batch Holati: 19840/60000 (33%) | Loss: 0.024921\n",
            "Train Epoch: 7 | Batch Holati: 20480/60000 (34%) | Loss: 0.018850\n",
            "Train Epoch: 7 | Batch Holati: 21120/60000 (35%) | Loss: 0.023047\n",
            "Train Epoch: 7 | Batch Holati: 21760/60000 (36%) | Loss: 0.204846\n",
            "Train Epoch: 7 | Batch Holati: 22400/60000 (37%) | Loss: 0.022018\n",
            "Train Epoch: 7 | Batch Holati: 23040/60000 (38%) | Loss: 0.019673\n",
            "Train Epoch: 7 | Batch Holati: 23680/60000 (39%) | Loss: 0.047278\n",
            "Train Epoch: 7 | Batch Holati: 24320/60000 (41%) | Loss: 0.041308\n",
            "Train Epoch: 7 | Batch Holati: 24960/60000 (42%) | Loss: 0.140241\n",
            "Train Epoch: 7 | Batch Holati: 25600/60000 (43%) | Loss: 0.035048\n",
            "Train Epoch: 7 | Batch Holati: 26240/60000 (44%) | Loss: 0.026946\n",
            "Train Epoch: 7 | Batch Holati: 26880/60000 (45%) | Loss: 0.045044\n",
            "Train Epoch: 7 | Batch Holati: 27520/60000 (46%) | Loss: 0.035708\n",
            "Train Epoch: 7 | Batch Holati: 28160/60000 (47%) | Loss: 0.017621\n",
            "Train Epoch: 7 | Batch Holati: 28800/60000 (48%) | Loss: 0.038595\n",
            "Train Epoch: 7 | Batch Holati: 29440/60000 (49%) | Loss: 0.041757\n",
            "Train Epoch: 7 | Batch Holati: 30080/60000 (50%) | Loss: 0.016045\n",
            "Train Epoch: 7 | Batch Holati: 30720/60000 (51%) | Loss: 0.031157\n",
            "Train Epoch: 7 | Batch Holati: 31360/60000 (52%) | Loss: 0.063407\n",
            "Train Epoch: 7 | Batch Holati: 32000/60000 (53%) | Loss: 0.079228\n",
            "Train Epoch: 7 | Batch Holati: 32640/60000 (54%) | Loss: 0.049749\n",
            "Train Epoch: 7 | Batch Holati: 33280/60000 (55%) | Loss: 0.076248\n",
            "Train Epoch: 7 | Batch Holati: 33920/60000 (57%) | Loss: 0.042812\n",
            "Train Epoch: 7 | Batch Holati: 34560/60000 (58%) | Loss: 0.182756\n",
            "Train Epoch: 7 | Batch Holati: 35200/60000 (59%) | Loss: 0.084622\n",
            "Train Epoch: 7 | Batch Holati: 35840/60000 (60%) | Loss: 0.009474\n",
            "Train Epoch: 7 | Batch Holati: 36480/60000 (61%) | Loss: 0.048597\n",
            "Train Epoch: 7 | Batch Holati: 37120/60000 (62%) | Loss: 0.017258\n",
            "Train Epoch: 7 | Batch Holati: 37760/60000 (63%) | Loss: 0.133571\n",
            "Train Epoch: 7 | Batch Holati: 38400/60000 (64%) | Loss: 0.029116\n",
            "Train Epoch: 7 | Batch Holati: 39040/60000 (65%) | Loss: 0.013077\n",
            "Train Epoch: 7 | Batch Holati: 39680/60000 (66%) | Loss: 0.083568\n",
            "Train Epoch: 7 | Batch Holati: 40320/60000 (67%) | Loss: 0.088578\n",
            "Train Epoch: 7 | Batch Holati: 40960/60000 (68%) | Loss: 0.052922\n",
            "Train Epoch: 7 | Batch Holati: 41600/60000 (69%) | Loss: 0.027577\n",
            "Train Epoch: 7 | Batch Holati: 42240/60000 (70%) | Loss: 0.057976\n",
            "Train Epoch: 7 | Batch Holati: 42880/60000 (71%) | Loss: 0.143784\n",
            "Train Epoch: 7 | Batch Holati: 43520/60000 (72%) | Loss: 0.035432\n",
            "Train Epoch: 7 | Batch Holati: 44160/60000 (74%) | Loss: 0.184184\n",
            "Train Epoch: 7 | Batch Holati: 44800/60000 (75%) | Loss: 0.032543\n",
            "Train Epoch: 7 | Batch Holati: 45440/60000 (76%) | Loss: 0.135049\n",
            "Train Epoch: 7 | Batch Holati: 46080/60000 (77%) | Loss: 0.045863\n",
            "Train Epoch: 7 | Batch Holati: 46720/60000 (78%) | Loss: 0.125136\n",
            "Train Epoch: 7 | Batch Holati: 47360/60000 (79%) | Loss: 0.029462\n",
            "Train Epoch: 7 | Batch Holati: 48000/60000 (80%) | Loss: 0.096109\n",
            "Train Epoch: 7 | Batch Holati: 48640/60000 (81%) | Loss: 0.018507\n",
            "Train Epoch: 7 | Batch Holati: 49280/60000 (82%) | Loss: 0.052514\n",
            "Train Epoch: 7 | Batch Holati: 49920/60000 (83%) | Loss: 0.055675\n",
            "Train Epoch: 7 | Batch Holati: 50560/60000 (84%) | Loss: 0.076155\n",
            "Train Epoch: 7 | Batch Holati: 51200/60000 (85%) | Loss: 0.032149\n",
            "Train Epoch: 7 | Batch Holati: 51840/60000 (86%) | Loss: 0.022459\n",
            "Train Epoch: 7 | Batch Holati: 52480/60000 (87%) | Loss: 0.015131\n",
            "Train Epoch: 7 | Batch Holati: 53120/60000 (88%) | Loss: 0.026005\n",
            "Train Epoch: 7 | Batch Holati: 53760/60000 (90%) | Loss: 0.011162\n",
            "Train Epoch: 7 | Batch Holati: 54400/60000 (91%) | Loss: 0.085769\n",
            "Train Epoch: 7 | Batch Holati: 55040/60000 (92%) | Loss: 0.040809\n",
            "Train Epoch: 7 | Batch Holati: 55680/60000 (93%) | Loss: 0.020009\n",
            "Train Epoch: 7 | Batch Holati: 56320/60000 (94%) | Loss: 0.120458\n",
            "Train Epoch: 7 | Batch Holati: 56960/60000 (95%) | Loss: 0.127495\n",
            "Train Epoch: 7 | Batch Holati: 57600/60000 (96%) | Loss: 0.033782\n",
            "Train Epoch: 7 | Batch Holati: 58240/60000 (97%) | Loss: 0.228106\n",
            "Train Epoch: 7 | Batch Holati: 58880/60000 (98%) | Loss: 0.101280\n",
            "Train Epoch: 7 | Batch Holati: 59520/60000 (99%) | Loss: 0.058087\n",
            "Training uchun ketgan vaqt: 0m 9s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0561, Accuracy: 9816/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 8 | Batch Holati: 0/60000 (0%) | Loss: 0.152561\n",
            "Train Epoch: 8 | Batch Holati: 640/60000 (1%) | Loss: 0.059647\n",
            "Train Epoch: 8 | Batch Holati: 1280/60000 (2%) | Loss: 0.157447\n",
            "Train Epoch: 8 | Batch Holati: 1920/60000 (3%) | Loss: 0.054963\n",
            "Train Epoch: 8 | Batch Holati: 2560/60000 (4%) | Loss: 0.031531\n",
            "Train Epoch: 8 | Batch Holati: 3200/60000 (5%) | Loss: 0.046906\n",
            "Train Epoch: 8 | Batch Holati: 3840/60000 (6%) | Loss: 0.146580\n",
            "Train Epoch: 8 | Batch Holati: 4480/60000 (7%) | Loss: 0.051411\n",
            "Train Epoch: 8 | Batch Holati: 5120/60000 (9%) | Loss: 0.121309\n",
            "Train Epoch: 8 | Batch Holati: 5760/60000 (10%) | Loss: 0.099986\n",
            "Train Epoch: 8 | Batch Holati: 6400/60000 (11%) | Loss: 0.049158\n",
            "Train Epoch: 8 | Batch Holati: 7040/60000 (12%) | Loss: 0.107732\n",
            "Train Epoch: 8 | Batch Holati: 7680/60000 (13%) | Loss: 0.042724\n",
            "Train Epoch: 8 | Batch Holati: 8320/60000 (14%) | Loss: 0.049599\n",
            "Train Epoch: 8 | Batch Holati: 8960/60000 (15%) | Loss: 0.069963\n",
            "Train Epoch: 8 | Batch Holati: 9600/60000 (16%) | Loss: 0.017402\n",
            "Train Epoch: 8 | Batch Holati: 10240/60000 (17%) | Loss: 0.228940\n",
            "Train Epoch: 8 | Batch Holati: 10880/60000 (18%) | Loss: 0.106845\n",
            "Train Epoch: 8 | Batch Holati: 11520/60000 (19%) | Loss: 0.022747\n",
            "Train Epoch: 8 | Batch Holati: 12160/60000 (20%) | Loss: 0.122229\n",
            "Train Epoch: 8 | Batch Holati: 12800/60000 (21%) | Loss: 0.114502\n",
            "Train Epoch: 8 | Batch Holati: 13440/60000 (22%) | Loss: 0.052457\n",
            "Train Epoch: 8 | Batch Holati: 14080/60000 (23%) | Loss: 0.098882\n",
            "Train Epoch: 8 | Batch Holati: 14720/60000 (25%) | Loss: 0.057349\n",
            "Train Epoch: 8 | Batch Holati: 15360/60000 (26%) | Loss: 0.090273\n",
            "Train Epoch: 8 | Batch Holati: 16000/60000 (27%) | Loss: 0.117194\n",
            "Train Epoch: 8 | Batch Holati: 16640/60000 (28%) | Loss: 0.162487\n",
            "Train Epoch: 8 | Batch Holati: 17280/60000 (29%) | Loss: 0.030900\n",
            "Train Epoch: 8 | Batch Holati: 17920/60000 (30%) | Loss: 0.034518\n",
            "Train Epoch: 8 | Batch Holati: 18560/60000 (31%) | Loss: 0.025401\n",
            "Train Epoch: 8 | Batch Holati: 19200/60000 (32%) | Loss: 0.208372\n",
            "Train Epoch: 8 | Batch Holati: 19840/60000 (33%) | Loss: 0.024459\n",
            "Train Epoch: 8 | Batch Holati: 20480/60000 (34%) | Loss: 0.049677\n",
            "Train Epoch: 8 | Batch Holati: 21120/60000 (35%) | Loss: 0.022398\n",
            "Train Epoch: 8 | Batch Holati: 21760/60000 (36%) | Loss: 0.026020\n",
            "Train Epoch: 8 | Batch Holati: 22400/60000 (37%) | Loss: 0.052858\n",
            "Train Epoch: 8 | Batch Holati: 23040/60000 (38%) | Loss: 0.036313\n",
            "Train Epoch: 8 | Batch Holati: 23680/60000 (39%) | Loss: 0.088958\n",
            "Train Epoch: 8 | Batch Holati: 24320/60000 (41%) | Loss: 0.085672\n",
            "Train Epoch: 8 | Batch Holati: 24960/60000 (42%) | Loss: 0.069339\n",
            "Train Epoch: 8 | Batch Holati: 25600/60000 (43%) | Loss: 0.161282\n",
            "Train Epoch: 8 | Batch Holati: 26240/60000 (44%) | Loss: 0.026733\n",
            "Train Epoch: 8 | Batch Holati: 26880/60000 (45%) | Loss: 0.080237\n",
            "Train Epoch: 8 | Batch Holati: 27520/60000 (46%) | Loss: 0.118343\n",
            "Train Epoch: 8 | Batch Holati: 28160/60000 (47%) | Loss: 0.040438\n",
            "Train Epoch: 8 | Batch Holati: 28800/60000 (48%) | Loss: 0.052684\n",
            "Train Epoch: 8 | Batch Holati: 29440/60000 (49%) | Loss: 0.014032\n",
            "Train Epoch: 8 | Batch Holati: 30080/60000 (50%) | Loss: 0.086595\n",
            "Train Epoch: 8 | Batch Holati: 30720/60000 (51%) | Loss: 0.034891\n",
            "Train Epoch: 8 | Batch Holati: 31360/60000 (52%) | Loss: 0.096420\n",
            "Train Epoch: 8 | Batch Holati: 32000/60000 (53%) | Loss: 0.136251\n",
            "Train Epoch: 8 | Batch Holati: 32640/60000 (54%) | Loss: 0.168047\n",
            "Train Epoch: 8 | Batch Holati: 33280/60000 (55%) | Loss: 0.050201\n",
            "Train Epoch: 8 | Batch Holati: 33920/60000 (57%) | Loss: 0.134612\n",
            "Train Epoch: 8 | Batch Holati: 34560/60000 (58%) | Loss: 0.032933\n",
            "Train Epoch: 8 | Batch Holati: 35200/60000 (59%) | Loss: 0.064593\n",
            "Train Epoch: 8 | Batch Holati: 35840/60000 (60%) | Loss: 0.101182\n",
            "Train Epoch: 8 | Batch Holati: 36480/60000 (61%) | Loss: 0.020772\n",
            "Train Epoch: 8 | Batch Holati: 37120/60000 (62%) | Loss: 0.184373\n",
            "Train Epoch: 8 | Batch Holati: 37760/60000 (63%) | Loss: 0.021660\n",
            "Train Epoch: 8 | Batch Holati: 38400/60000 (64%) | Loss: 0.035109\n",
            "Train Epoch: 8 | Batch Holati: 39040/60000 (65%) | Loss: 0.038881\n",
            "Train Epoch: 8 | Batch Holati: 39680/60000 (66%) | Loss: 0.050843\n",
            "Train Epoch: 8 | Batch Holati: 40320/60000 (67%) | Loss: 0.018369\n",
            "Train Epoch: 8 | Batch Holati: 40960/60000 (68%) | Loss: 0.020197\n",
            "Train Epoch: 8 | Batch Holati: 41600/60000 (69%) | Loss: 0.083600\n",
            "Train Epoch: 8 | Batch Holati: 42240/60000 (70%) | Loss: 0.041312\n",
            "Train Epoch: 8 | Batch Holati: 42880/60000 (71%) | Loss: 0.005114\n",
            "Train Epoch: 8 | Batch Holati: 43520/60000 (72%) | Loss: 0.102654\n",
            "Train Epoch: 8 | Batch Holati: 44160/60000 (74%) | Loss: 0.113355\n",
            "Train Epoch: 8 | Batch Holati: 44800/60000 (75%) | Loss: 0.175368\n",
            "Train Epoch: 8 | Batch Holati: 45440/60000 (76%) | Loss: 0.022543\n",
            "Train Epoch: 8 | Batch Holati: 46080/60000 (77%) | Loss: 0.021669\n",
            "Train Epoch: 8 | Batch Holati: 46720/60000 (78%) | Loss: 0.100483\n",
            "Train Epoch: 8 | Batch Holati: 47360/60000 (79%) | Loss: 0.036740\n",
            "Train Epoch: 8 | Batch Holati: 48000/60000 (80%) | Loss: 0.053568\n",
            "Train Epoch: 8 | Batch Holati: 48640/60000 (81%) | Loss: 0.103814\n",
            "Train Epoch: 8 | Batch Holati: 49280/60000 (82%) | Loss: 0.009778\n",
            "Train Epoch: 8 | Batch Holati: 49920/60000 (83%) | Loss: 0.093786\n",
            "Train Epoch: 8 | Batch Holati: 50560/60000 (84%) | Loss: 0.056436\n",
            "Train Epoch: 8 | Batch Holati: 51200/60000 (85%) | Loss: 0.057499\n",
            "Train Epoch: 8 | Batch Holati: 51840/60000 (86%) | Loss: 0.102940\n",
            "Train Epoch: 8 | Batch Holati: 52480/60000 (87%) | Loss: 0.012331\n",
            "Train Epoch: 8 | Batch Holati: 53120/60000 (88%) | Loss: 0.024086\n",
            "Train Epoch: 8 | Batch Holati: 53760/60000 (90%) | Loss: 0.039515\n",
            "Train Epoch: 8 | Batch Holati: 54400/60000 (91%) | Loss: 0.077009\n",
            "Train Epoch: 8 | Batch Holati: 55040/60000 (92%) | Loss: 0.115395\n",
            "Train Epoch: 8 | Batch Holati: 55680/60000 (93%) | Loss: 0.023084\n",
            "Train Epoch: 8 | Batch Holati: 56320/60000 (94%) | Loss: 0.038327\n",
            "Train Epoch: 8 | Batch Holati: 56960/60000 (95%) | Loss: 0.019505\n",
            "Train Epoch: 8 | Batch Holati: 57600/60000 (96%) | Loss: 0.024043\n",
            "Train Epoch: 8 | Batch Holati: 58240/60000 (97%) | Loss: 0.043315\n",
            "Train Epoch: 8 | Batch Holati: 58880/60000 (98%) | Loss: 0.011750\n",
            "Train Epoch: 8 | Batch Holati: 59520/60000 (99%) | Loss: 0.077331\n",
            "Training uchun ketgan vaqt: 0m 9s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0542, Accuracy: 9820/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Train Epoch: 9 | Batch Holati: 0/60000 (0%) | Loss: 0.069430\n",
            "Train Epoch: 9 | Batch Holati: 640/60000 (1%) | Loss: 0.010721\n",
            "Train Epoch: 9 | Batch Holati: 1280/60000 (2%) | Loss: 0.011923\n",
            "Train Epoch: 9 | Batch Holati: 1920/60000 (3%) | Loss: 0.073474\n",
            "Train Epoch: 9 | Batch Holati: 2560/60000 (4%) | Loss: 0.023205\n",
            "Train Epoch: 9 | Batch Holati: 3200/60000 (5%) | Loss: 0.007941\n",
            "Train Epoch: 9 | Batch Holati: 3840/60000 (6%) | Loss: 0.046387\n",
            "Train Epoch: 9 | Batch Holati: 4480/60000 (7%) | Loss: 0.006710\n",
            "Train Epoch: 9 | Batch Holati: 5120/60000 (9%) | Loss: 0.014578\n",
            "Train Epoch: 9 | Batch Holati: 5760/60000 (10%) | Loss: 0.009368\n",
            "Train Epoch: 9 | Batch Holati: 6400/60000 (11%) | Loss: 0.023948\n",
            "Train Epoch: 9 | Batch Holati: 7040/60000 (12%) | Loss: 0.102812\n",
            "Train Epoch: 9 | Batch Holati: 7680/60000 (13%) | Loss: 0.061349\n",
            "Train Epoch: 9 | Batch Holati: 8320/60000 (14%) | Loss: 0.041674\n",
            "Train Epoch: 9 | Batch Holati: 8960/60000 (15%) | Loss: 0.048445\n",
            "Train Epoch: 9 | Batch Holati: 9600/60000 (16%) | Loss: 0.077092\n",
            "Train Epoch: 9 | Batch Holati: 10240/60000 (17%) | Loss: 0.114342\n",
            "Train Epoch: 9 | Batch Holati: 10880/60000 (18%) | Loss: 0.014989\n",
            "Train Epoch: 9 | Batch Holati: 11520/60000 (19%) | Loss: 0.057111\n",
            "Train Epoch: 9 | Batch Holati: 12160/60000 (20%) | Loss: 0.014073\n",
            "Train Epoch: 9 | Batch Holati: 12800/60000 (21%) | Loss: 0.034614\n",
            "Train Epoch: 9 | Batch Holati: 13440/60000 (22%) | Loss: 0.045174\n",
            "Train Epoch: 9 | Batch Holati: 14080/60000 (23%) | Loss: 0.018807\n",
            "Train Epoch: 9 | Batch Holati: 14720/60000 (25%) | Loss: 0.017971\n",
            "Train Epoch: 9 | Batch Holati: 15360/60000 (26%) | Loss: 0.080294\n",
            "Train Epoch: 9 | Batch Holati: 16000/60000 (27%) | Loss: 0.017546\n",
            "Train Epoch: 9 | Batch Holati: 16640/60000 (28%) | Loss: 0.057595\n",
            "Train Epoch: 9 | Batch Holati: 17280/60000 (29%) | Loss: 0.028193\n",
            "Train Epoch: 9 | Batch Holati: 17920/60000 (30%) | Loss: 0.134372\n",
            "Train Epoch: 9 | Batch Holati: 18560/60000 (31%) | Loss: 0.077788\n",
            "Train Epoch: 9 | Batch Holati: 19200/60000 (32%) | Loss: 0.101205\n",
            "Train Epoch: 9 | Batch Holati: 19840/60000 (33%) | Loss: 0.051088\n",
            "Train Epoch: 9 | Batch Holati: 20480/60000 (34%) | Loss: 0.068151\n",
            "Train Epoch: 9 | Batch Holati: 21120/60000 (35%) | Loss: 0.081311\n",
            "Train Epoch: 9 | Batch Holati: 21760/60000 (36%) | Loss: 0.017203\n",
            "Train Epoch: 9 | Batch Holati: 22400/60000 (37%) | Loss: 0.035575\n",
            "Train Epoch: 9 | Batch Holati: 23040/60000 (38%) | Loss: 0.005967\n",
            "Train Epoch: 9 | Batch Holati: 23680/60000 (39%) | Loss: 0.009347\n",
            "Train Epoch: 9 | Batch Holati: 24320/60000 (41%) | Loss: 0.121505\n",
            "Train Epoch: 9 | Batch Holati: 24960/60000 (42%) | Loss: 0.049171\n",
            "Train Epoch: 9 | Batch Holati: 25600/60000 (43%) | Loss: 0.029832\n",
            "Train Epoch: 9 | Batch Holati: 26240/60000 (44%) | Loss: 0.100541\n",
            "Train Epoch: 9 | Batch Holati: 26880/60000 (45%) | Loss: 0.013192\n",
            "Train Epoch: 9 | Batch Holati: 27520/60000 (46%) | Loss: 0.019546\n",
            "Train Epoch: 9 | Batch Holati: 28160/60000 (47%) | Loss: 0.030446\n",
            "Train Epoch: 9 | Batch Holati: 28800/60000 (48%) | Loss: 0.180271\n",
            "Train Epoch: 9 | Batch Holati: 29440/60000 (49%) | Loss: 0.077677\n",
            "Train Epoch: 9 | Batch Holati: 30080/60000 (50%) | Loss: 0.065133\n",
            "Train Epoch: 9 | Batch Holati: 30720/60000 (51%) | Loss: 0.019832\n",
            "Train Epoch: 9 | Batch Holati: 31360/60000 (52%) | Loss: 0.027783\n",
            "Train Epoch: 9 | Batch Holati: 32000/60000 (53%) | Loss: 0.032248\n",
            "Train Epoch: 9 | Batch Holati: 32640/60000 (54%) | Loss: 0.052947\n",
            "Train Epoch: 9 | Batch Holati: 33280/60000 (55%) | Loss: 0.028306\n",
            "Train Epoch: 9 | Batch Holati: 33920/60000 (57%) | Loss: 0.171393\n",
            "Train Epoch: 9 | Batch Holati: 34560/60000 (58%) | Loss: 0.056032\n",
            "Train Epoch: 9 | Batch Holati: 35200/60000 (59%) | Loss: 0.012225\n",
            "Train Epoch: 9 | Batch Holati: 35840/60000 (60%) | Loss: 0.009799\n",
            "Train Epoch: 9 | Batch Holati: 36480/60000 (61%) | Loss: 0.116849\n",
            "Train Epoch: 9 | Batch Holati: 37120/60000 (62%) | Loss: 0.024879\n",
            "Train Epoch: 9 | Batch Holati: 37760/60000 (63%) | Loss: 0.064228\n",
            "Train Epoch: 9 | Batch Holati: 38400/60000 (64%) | Loss: 0.078290\n",
            "Train Epoch: 9 | Batch Holati: 39040/60000 (65%) | Loss: 0.114948\n",
            "Train Epoch: 9 | Batch Holati: 39680/60000 (66%) | Loss: 0.122681\n",
            "Train Epoch: 9 | Batch Holati: 40320/60000 (67%) | Loss: 0.027747\n",
            "Train Epoch: 9 | Batch Holati: 40960/60000 (68%) | Loss: 0.022526\n",
            "Train Epoch: 9 | Batch Holati: 41600/60000 (69%) | Loss: 0.057345\n",
            "Train Epoch: 9 | Batch Holati: 42240/60000 (70%) | Loss: 0.090760\n",
            "Train Epoch: 9 | Batch Holati: 42880/60000 (71%) | Loss: 0.108145\n",
            "Train Epoch: 9 | Batch Holati: 43520/60000 (72%) | Loss: 0.032803\n",
            "Train Epoch: 9 | Batch Holati: 44160/60000 (74%) | Loss: 0.041721\n",
            "Train Epoch: 9 | Batch Holati: 44800/60000 (75%) | Loss: 0.134150\n",
            "Train Epoch: 9 | Batch Holati: 45440/60000 (76%) | Loss: 0.038966\n",
            "Train Epoch: 9 | Batch Holati: 46080/60000 (77%) | Loss: 0.036885\n",
            "Train Epoch: 9 | Batch Holati: 46720/60000 (78%) | Loss: 0.097293\n",
            "Train Epoch: 9 | Batch Holati: 47360/60000 (79%) | Loss: 0.024720\n",
            "Train Epoch: 9 | Batch Holati: 48000/60000 (80%) | Loss: 0.047306\n",
            "Train Epoch: 9 | Batch Holati: 48640/60000 (81%) | Loss: 0.086173\n",
            "Train Epoch: 9 | Batch Holati: 49280/60000 (82%) | Loss: 0.017814\n",
            "Train Epoch: 9 | Batch Holati: 49920/60000 (83%) | Loss: 0.043354\n",
            "Train Epoch: 9 | Batch Holati: 50560/60000 (84%) | Loss: 0.117271\n",
            "Train Epoch: 9 | Batch Holati: 51200/60000 (85%) | Loss: 0.046325\n",
            "Train Epoch: 9 | Batch Holati: 51840/60000 (86%) | Loss: 0.013819\n",
            "Train Epoch: 9 | Batch Holati: 52480/60000 (87%) | Loss: 0.029812\n",
            "Train Epoch: 9 | Batch Holati: 53120/60000 (88%) | Loss: 0.120937\n",
            "Train Epoch: 9 | Batch Holati: 53760/60000 (90%) | Loss: 0.008389\n",
            "Train Epoch: 9 | Batch Holati: 54400/60000 (91%) | Loss: 0.030586\n",
            "Train Epoch: 9 | Batch Holati: 55040/60000 (92%) | Loss: 0.081055\n",
            "Train Epoch: 9 | Batch Holati: 55680/60000 (93%) | Loss: 0.009676\n",
            "Train Epoch: 9 | Batch Holati: 56320/60000 (94%) | Loss: 0.085248\n",
            "Train Epoch: 9 | Batch Holati: 56960/60000 (95%) | Loss: 0.083212\n",
            "Train Epoch: 9 | Batch Holati: 57600/60000 (96%) | Loss: 0.058969\n",
            "Train Epoch: 9 | Batch Holati: 58240/60000 (97%) | Loss: 0.046616\n",
            "Train Epoch: 9 | Batch Holati: 58880/60000 (98%) | Loss: 0.131463\n",
            "Train Epoch: 9 | Batch Holati: 59520/60000 (99%) | Loss: 0.014391\n",
            "Training uchun ketgan vaqt: 0m 10s\n",
            "\n",
            "Test set : Average(ortach) loss: 0.0505, Accuracy: 9842/10000 (98%)\n",
            "Test uchun ketgan vaqt: 0m 11s\n",
            "Umumiy vaqt: 1m 47s\n",
            "Model  cuda qurilmada train qilindi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelni yuklab olish"
      ],
      "metadata": {
        "id": "xSngfHJNYHlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model,'Numbers_model.pkl')"
      ],
      "metadata": {
        "id": "hskcz5klxc0m"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Numbers_model=torch.load('Numbers_model.pkl')"
      ],
      "metadata": {
        "id": "8WMp-IwGBlV9"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}